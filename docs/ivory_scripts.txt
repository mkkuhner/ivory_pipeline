Automated scripts for analyzing new elephant ivory seizure data

This pipeline is specific for African elephants with the 16
microsatellite data set.  It will need modification to accomodate
other species or types of data. 

Code and reference data for this pipeline are in the private GitHub
repository https://github.com/mkkuhner/ivory_pipeline.  Within that
repository, programs and scripts are in the /src directory,
additional files needed to run the scripts are in the /aux
directory, and documentation files are in the /docs directory.

WARNING:  Never check anything into the GitHub repository which is
law enforcement sensitive or otherwise high security.  

The pipeline also relies on the following code found in other
respositories:

SCAT -- https://github.com/stephens999/scat
VORONOI -- https://github.com/stephens999/voronoi
EBhybrids -- https://github.com/stephenslab/EBhybrids
Familial Matching -- https://github.com/cwolock/elephant_fam_match
Structure -- https://web.stanford.edu/group/pritchardlab/structure_software/release_versions/v2.3.4/html/structure.html

Currently the ivorydata/src directory does not include Structure, SCAT or
VORONOI, but does include copies of EBhybrids and Familial Matching.
If these programs are updated, replace these copies!

***General Rules

1)  All Python scripts are Python3.

2)  The term [species] refers to either "savannah" or "forest".

3)  The term [date] refers to a date in format YYYY_MM_DD (e.g.  2021_01_30).

4)  The term [DBno] refers to the numeric ID of a release of the Master Elephant 
Genotypes file.

***Automated scripts vs. running by hand

This document covers the use of automated scripts to run all parts of the
pipeline except for SCAT (not automated because you may wish to run it on
the cluster).  For directions on running individual programs by hand, see 
ivory_pipeline.txt.

***A)  Obtain all needed files

1)  If you do not have up-to-date installations of the following programs:

SCAT
VORONOI
EBhybrids
Familial Matching
Structure

obtain and install them now.  Detailed instructions are in document 
installing_software.txt in the ivory_pipeline directory. 

2)  Obtain the seizure data files.  Files with elephant genotypes, reference or 
seizure, are not kept in the online repositories for security reasons.  Yves 
Horeau can provide the most recent copy of the master elephant genotypes file, 
which can be used as a source for reference data and previously analyzed 
seizure data.  Data for a brand new seizure is generally not yet in this file; 
it should be requested from the laboratory staff who genotyped it.

You will minimally need the Master Elephant Genotype file, which is 
distributed as a .xlsx file, unfortunately with variations in its name.  
It may be something like:

Elephant_Genotypes_Master_[DBno].xlsx
ElephantMasterFile[DBno].xlsx

If your seizure has not yet been added to this file, you will also need a 
data file containing its genotypes; this will generally be an .xlsx file 
but its name is arbitrary.  (Also ask them what the official name of the 
new seizure is.)

3)  Obtain the reference data and reference Structure runs. 

Needed files:

REFELE_[DBno]_raw.txt                  (raw reference data)
REFELE_[DBno]_known.txt                (formatted reference data)
REFELE_[DBno]_known_structure.txt_f    (Structure results)
REFELE_[DBno}_filtered_[species].txt   ("canned" reference data)

If you do not have these files, steps to prepare them are in 
/docs/reference_pipeline.txt.

4)  Prepare a pathnames file.

This file must be named "ivory_paths.tsv" and must be placed in the
parent directory of your seizure runs.  It gives pathname information to find
all necessary files for the run.  Lines within this file can be in any
order; entries within the same line must be in order and must be separated
with tabs, not spaces.  Directory names should end in "/".

A sample ivory_paths.tsv file can be found in

ivory_pipeline/aux/ivory_paths.tsv

but will need to be modified for your own directory structure.

The first entry of each line in ivory_paths.tsv names a particular required 
directory or file.  The second entry gives a path to find it; for lines with 
a third entry, this gives the prefix of the file (useful when there are several 
related files such as _forest and _savannah variants). 

Lines in this file are as follows:

ivory_pipeline_dir	path to the ivory_pipeline root directory	
scat_executable		path and filename of the SCAT executable
voronoi_executable	path and filename of the VORONOI executable
reference_prefix	path to the reference data files	prefix of these files
zones_prefix		path to zones files			prefix of these files
metadata_prefix		path to seizure metadata		prefix of this file
seizure_modifications_prefix	path to modifications file	prefix of this file
map_prefix		path to map files			prefix of these files
seizure_data_dir	directory where raw seizure data is kept
structure_executable	path and filename of the Structure executable
fammatch_archive_dir	path to familial matching input file archive

***B)  Preprocess the data for analysis

1)  Pick a PREFIX (ideally the official name of the seizure) that will 
tag all runs for this case.

2)  Extract the seizure genotype data.  For a new seizure, open the
spreadsheet and look for a tab labeled "Scat input".  To use data
from older seizures which are already in the database, refer to the 
documentation file master_database_pipeline.txt.

Extract the "Scat input" data from the spreadsheet as a .tsv file; this
can be done with LibreOffice by saving the file as .csv but setting the 
delimiter to tab rather than comma, and then changing the name of the
resulting file.  Name this file PREFIX_raw.tsv and place it in the directory
you have indicated (in ivory_paths.tsv) as containing seizure data files.

***C)  Data preparation and SCAT run setup

The Python program "phase1.py" begins with raw seizure data.  It validates
the data, classifies it by species, removes hybrids, and prepares the data
for SCAT.  It also sets up directories and runfiles for running SCAT.

Because the user may want to run SCAT on the cluster, this program does 
not actually start the SCAT runs; this must be done by hand.

The phase1.py program takes PREFIX as its first argument and either "laptop"
or "cluster" as its second.  Use "laptop" for running on your own machine
(whether it is actually a laptop or not) and "cluster" for running on the
Biology HYAK cluster using SLURM.  Note that if you plan to use the cluster for
your SCAT runs, you will still run phase1.py on your own machine and then
transfer the resulting SCAT run directories to the cluster for execution.
(We have not tested steps other than SCAT on the cluster and they are not
likely to work there without modification.)

Programs run by phase1.py check for unexpected microsatellite alleles and
for duplicate samples.  The program will terminate with an error message if
these are encountered.  For details on these checks, see ivory_pipeline.txt.

***D) Running SCAT

1)  Running on your own machine

Program phase1.py will have created a directory named PREFIX.  Within it
will be either one or two species-specific directories named /nsavannah and
/nforest.  If no samples from that species were found the corresponding directory
will not be present.  You will need to run SCAT separately for each species.
Change directory into nforest or nsavannah; you will find nine
directories named "1" through "9".  You will run SCAT in each of these
directories.  It is convenient to open a separate window for each one; they
can all run at once if your machine is sufficiently powerful.

From inside directory number N, use the command "source runN.sh" to run SCAT.
It may take hours or days to run, depending on the number of samples in your
seizure.  Do NOT run subsequent scripts (phase2.py, phase3.py) until the
SCAT runs have all finished.

To run on the cluster, consult cluster documentation.

TO DO:  document running on the cluster.


***E)  Running VORONOI

The script phase2.py sets up and runs VORONOI.  It should be run in the 
parent directory of all seizures, and expects to find ivory_paths.tsv in 
that directory.  It takes PREFIX as its argument. 

This script sets up the VORONOI run, executes it, and creates plots of
the results.  VORONOI outputs will be found in /nforest and/or /nsavannah.
Plots will be found in a subdirectory of /nforest and/or /nsavannah called
PREFIX_reports.  Each sample will have a SCAT heatmap and a VORONOI
heatmap.  There will also be three summary files as follows:

scat_summary_medians.png  -- SCAT results summarized as median latitude and longitude
scat_summary_squares.png  -- SCAT results summarized as maximal 1-degree square
voronoi_summary.png       -- VORONOI results summarized as maximal 1-degree square

Finally, there will be a file called PREFIX_point_estimates.tsv, which gives
the same information as the three summary files, but in textual form.

TO DO:  write a note on how to install Cartopy:  it's tricky.


***F)  Run familial matching

This document explains how to do familial matching of a new seizure when
all previous seizures have already been run and archived.  If
you need to do familial matching on the entire data set at once, see 
documentation file familial_pipeline.txt, and be aware that it will 
take 3+ days.  Rerunning the whole thing is needed if large changes 
have been made to the reference data, the sector definitions have 
changed, or the set of previous seizures to be used has changed.

This is carried out by the script phase3.py.  It is meant to be run in the
parent directory of all seizures, and takes PREFIX as its argument.
Inefficiently, it does the familial matching R script runs one at a time.
They can all be run at once safely, but downstream code must not execute
until they have all completed, and I have not figured out how to code that.

At the end of this program, there will exist a "fammatch" directory in
seizure directory PREFIX, with up to 6 subdirectories called "subN".
Each represents results for this seizure in a particular sector (sector N)
and will be present only if the seizure has samples assigned to that
sector.

In each "subN" directory, there will be a file called 

obsLRs.[species].seizures.[cutoff].filtered.txt

which contains matches within the current seizure and between the current seizure and
all previous ones in the archive.  It prints only matches which reach the specified cutoff,
currently 2.0.  These results can be used for a quick and dirty evaluation of matches,
but matches with relatively low logLR scores have a high chance of being false positives,
especially in savannah.

The script does not yet recalculate false positive rates.
