Protocol for analyzing new elephant ivory seizure data

This pipeline is specific for African elephants with the 16
microsatellite data set.  It will need modification to accomodate
other species or types of data.

Code and reference data for this pipeline are in the private GitHub
repository https://github.com/mkkuhner/ivory_pipeline.  Within that
repository, programs and scripts are in the src directory,
additional files needed to run the scripts are in the auxillary_files
directory, reference data are in the data directory, and documentation 
files are in the docs directory.

WARNING:  Never check anything into the GitHub repository which is
law enforcement sensitive or otherwise high security.  

The pipeline also relies on the following code found in other
respositories:

SCAT -- https://github.com/stephens999/scat
VORONOI -- https://github.com/stephens999/voronoi
EBhybrids -- https://github.com/stephenslab/EBhybrids
Familial Matching -- https://github.com/cwolock/elephant_fam_match
Structure -- https://web.stanford.edu/group/pritchardlab/structure_software/release_versions/v2.3.4/html/structure.html

Currently the ivorydata/src directory does not include Structure, SCAT or
VORONOI, but does include copies of EBhybrids and Familial Matching.

All Python scripts are Python3 except for step F3 (programs plot_scat_vor.py
and plot_scat.py), which must be run in Python2 as they use the "basemap" 
library.  We do not currently have a workaround if "basemap" is unavailable,
and as it is deprecated, it may not be available for much longer.  

***General Rules

1)  The term [species] refers to either savannah or forest.

2)  The term [date] refers to a date in format YYYY_MM_DD (e.g.
2021_01_30.

3)  The term [DBno] refers to the numeric ID of a release of the Master Elephant Genotypes
file.

***A)  Obtaining all needed files

1)  If you do not have up-to-date installations of the following programs:

SCAT2
VORONOI
EBhybrids
Familial Matching
Structure

obtain and install them now.  Detailed instructions are in document 
installing_software.txt in the ivory_pipeline directory.

2)  Obtain the needed data files.  Files with elephant genotypes, reference or 
seizure, are not kept in the online repositories for security reasons.  Yves 
Horeau can provide the most recent copy of the master elephant genotypes file, 
which can be used as a source for reference data and previously analyzed 
seizure data.  Data for a brand new seizure is generally not yet in this file; 
it should be requested from the laboratory staff who genotyped it.

You will minimally need the Master Elephant Genotype file, which is 
distributed as a .xlsx file, unfortunately with variations in its name.  
It may be something like:

Elephant_Genotypes_Master_[DBno].xlsx
ElephantMasterFile[DBno].xlsx

If your seizure has not yet been added to this file, you will also need a 
data file containing its genotypes; this will generally be an .xlsx file 
but its name is arbitrary.  (Also ask them what the official name of the 
new seizure is.)

***B)  Obtaining the reference data.

If you already have SCAT-style formatted reference data and the 
corresponding Structure results, you can stip this step.

These files would be called:

REFELE_[DBno]_known.txt                (formatted reference data)
REFELE_[DBno]_known_structure.txt_f    (Structure results)

If you do not have these files, steps to prepare them are in 
/docs/reference_pipeline.txt.

***C)  Preprocessing the data for analysis

1)  Pick a PREFIX (ideally the official name of the seizure) that will 
tag all runs for this case.

2)  Obtain the seizure genotype data.  For a new seizure, open the
spreadsheet and look for a tab labeled "Scat input".  To use data
from older seizures which are already in the database, refer to the 
documentation file master_database_pipeline.txt, which will replace step A3.

3)  Extract the "Scat input" data from the spreadsheet as a .tsv file; this
can be done with LibreOffice by saving the file as .csv but setting the 
delimiter to tab rather than comma, and then changing the name of the
resulting file.  Name this file PREFIX_raw.tsv.

4)  Run prep_scat_data.py with an argument of PREFIX. This will read
PREFIX_raw.tsv and write PREFIX_unknowns.txt.  This program marks the new data 
as region -1, and corrects msats where only one allele is missing to 
mark both as missing.  It also suppresses individuals with less
than 10 successfully typed microsatellites.  (These have often been
suppressed upstream by the author of the spreadsheet, but we double-
check here.)


***D)  Assigning species and identifying hybrids

This step relies on Structure results for the reference data; these
will be called REFELE_[DBno]_known_structure.txt_f.  The Structure
results MUST be for exactly the version of the database that you are
using; even a single elephant change will invalidate them.  If in
doubt, rerun.

1)  Obtain the appropriate allelic dropout file.  This is
currently "dropoutrates_savannahfirst.txt" and is in the auxillary_files 
directory.  (It is a columns reversed version of the original file from 
Mondol et al, which was named "Mondoletal_allelicdropoutrates.txt".)

Note:  In theory, you can create this file for novel data using R scripts, 
but I have never gotten them to run successfully.  The R scripts you would 
use are in the /src directory:

infermarkerspecnullalleleprob.R
infernullalleleprobanderrorprob.R

2)  Run make_eb_input.py.  Argument 1 is the Structure output file.  Argument 2
is REFELE_[DBno]_known.txt, the region-known reference data file.
Argument 3 is PREFIX.  Argument 4 is dropoutrates_savannahfirst.txt.
The script also assumes that file ebscript_template.R is present in its 
directory:  this file can be found in the auxillary_files directory of
the ivory_pipeline repository.  

There are three outputs.  

PREFIX_ancestryprops.txt gives the ancestry proportions needed by EBhybrids.  
Be careful with this file; it does not contain sample IDs, but relies on 
being in the same order as the other files written by make_eb_input.py.

PREFIX_plus_ref.txt contains genotype data for the seizure and all reference
individuals (both species).

ebscript.R is the EBhybrids run script modified to point at these files.
Note that if this file exists, it will be overwritten.

3)  Run ebscript.R (command is "Rscript ebscript.R").  This will run
EBhybrids and write four files:  PREFIX_hybt.csv and .txt, and PREFIX_HPs.csv
and .txt.  The hybt files give the probability that the sample is either pure
species or any of 4 hybrid types.  The HPs files give only the probability that
it is a hybrid.  Information is identical between .csv and .txt.


***E) Running SCAT2

We do not recommend using the built-in species ranges in SCAT2 or
the old-style boundary file 316forestboundary.txt.   The programs will
run, but the resulting boundaries are very poor (they include ocean and
exclude valid habitat).

1)  Obtain the following files and place in current directory:

-- Map files of choice; either the "full" map files mapfile_161220_[species].txt
or the IUCN map files iucn_161220_[species].txt.  These are found in the
auxillary_files directory.

-- Region file of choice.  The current version is regionfile.v38b. 
This is found in the auxillary_files directory.  The regionfile gives the
mapping between sampling location ("region") name, number, subregion,
and latitude/longitude.  If new sampling regions have been added to the
reference data, you will need to update this file and create a new
version.

-- Prototype SCAT2 and VORONOI run files master_scat_runfile.sh and
master_voronoi_runfile.sh.  These are found in the auxillary_files
directory; they are templates for creating run commands for your
SCAT2 and VORONOI runs.

OPTIONAL:  If you want a different SCAT2 run length than our standard one, 
edit the master_scat_runfile.sh file.  The last three numbers (currently 
100 20 100) control the length of the run:  the first is number of sampled 
iterations, the second is steps between samplings, and the third is burnin.
VORONOI assumes exactly 100 sampled iterations and 100 non-sampled 
iterations and would have to be modified to change this, so your best bet is
to change the steps between samplings.  Runtime will increase linearly with 
this (if you double steps between samplings, runtime will approximately 
double).

2)  Run make_species_files.py with the following arguments:

-- PREFIX of the run
-- Map prefix, for example mapfile_161220 or iucn_161220 (the part of
the mapfile name before the species name).
-- Regionfile name.  
-- Reference data prefix REFELE_[DBno]

The make_species_files.py program will print its hardwired hybrid cutoff to
screen.  Make sure this cutoff is what you want.

This program uses PREFIX_hybt.txt to sort the samples into, maximally, a 
forest and a savannah SCAT input file, called PREFIX_[species].txt;
if there are no unknown individuals from a species, that file will not be 
written.  It discards individuals called as hybrids.  

Outputs:

SCAT run files:  runfile_[species].sh
VORONOI run files:  voronoi_runfile_[species].sh
familial matching reference files:  REFELE_[DBno]_[species]_long.csv
familial matching genotype files:  PREFIX_genotypes_[species]_wide.csv

3)  Create a directory for each species-specific SCAT2 analysis.  All 
subsequent steps will have to be done for both directories, if you have both
species in your seizure.  (We typically name these directories "nforest"
and "nsavannah" but this is not required.  Copy the corresponding SCAT 
input files (PREFIX_[species].txt) into these directories.  Also copy 
in the corresponding Voronoi runfiles (voronoi_runfile_[species].sh).
However, leave the SCAT run files where they are.

Place a SCAT2 executable in this species-specific SCAT2 directory.  We 
recommend a clean optimized build from source.  

4)  Run setupscatruns.py with the following arguments (twice, if you
have both forest and savannah individuals):

-- name of the species-specific run directory
-- name of the master scat run script (runfile_[species].sh) 
-- random number seed (positive integer)

This seed will be used for the first directory and incremented by 1 for each
subsequent directory.

This will create 9 subdirectories named 1-9 under your named directory, each 
of which contains a SCAT2 run command file (called runX.sh where X is the 
directory number) and an /outputs directory to hold the results.

5)  Open a window for each numbered directory and run the runX.sh file (using
"source" as they are not executable files).  This should run SCAT2 nine
times.  It likely will take hours or days to run.


***F)  Running VORONOI

Do not do this step unless there were at least 2 samples in the species
under consideration:  running VORONOI on one sample is not useful.

1)  Obtain or prepare a masterfile consisting of 9 lines as follows (there
is an example, called "masterfile", in the auxillary_files directory) and
place it in the species-specific directory.

1/outputs
2/outputs 
...

2)  In the species-specific directory, run scat2voronoi.py
with the argument being the masterfile from step 1.  This writes multiple
files:

a)  A large number of files with names of the form nnnc where nnn are
digits and c is a character between r and z.  These are single elephant
SCAT result files:  001r is the result for the first elephant in directory
1.  If something goes wrong in subsequent steps, the first thing to check
is whether all of these files are present (often one letter of the
alphabet is missing, which likely indicates that one of the SCAT2 runs
has failed).

b)  Files named samplemap.r through samplemap.z which relate the nnn numbers
to elephant IDs.  In practice we only use samplemap.r; they should all be
identical.

c)  A file voronoiin.txt which instructs VORONOI on which samples (by
nnn identifier) it should run.

3)  Pull a VORONOI executable:  I recommend a clean optimized build from
source.

4)  Run VORONOI by source-ing the run command file present in the
species-specific directory (this file was written by make_species_files.py). 
It should take no more than 10-15 minutes for most data.


***G)  Post-processing


1)  Run prep_reports.py in the directory where you ran VORONOI.  Its
first argument is PREFIX and the second is the voronoiin.txt file you
used for the run.  It also uses the VORONOI output files PREFIX_indprobs and
PREFIX_mapinfo, and the samplemap.r file; it expects these files to be
present in the directory where it is being run (they are not arguments).  
It writes individual VORONOI grid files to a directory named PREFIX_reports.

2)  Run plot_scat_vor.py in the directory where you ran VORONOI.  It
takes 1 or 2 arguments.  If there is only 1 it is PREFIX, and all samples
will be run.  If there are 2, they are PREFIX and SID, and only the
sample with that SID will be run.  This fills up PREFIX_reports with
graphics of the SCAT2 and VORONOI surfaces for each sample, plus three
summary files:  

scat_summary_medians.jpg (SCAT2 results as median latitude/longitude)
scat_summary_squares.jpg (SCAT2 results as grid square of highest count)
voronoi_sumary.jpg (VORONOI results as grid square of highest posterior)

If you need SCAT2 graphics without VORONOI graphics, for example because
there was only 1 sample for this species, they can be gotten with
plot_scat.py with the same arguments.

NOTE:  Neither plot program for step 3 will run in Python3 as they
use Basemap.  They will not run on Jon's laptop at all.  They are
likely to stop working at all in the near future as Basemap is
being retired.

TO DO:  Convert to Cartopy library.

3)  OPTIONAL but recommended:  In the directory where you ran VORONOI,
run cleanup_voronoi.py with no arguments.  This deletes duplicate copies
of the SCAT2 output files, placed in this directory for use by VORONOI,
and saves a lot of space.  (These files are named 001r, 001s, etc.)  If 
you find that you need those files back, they can be recreated by rerunning 
scat2voronoi.py.


***H)  Familial matching

Recent versions of the familial matching code work with, in addition to
reference data, two files of seizure data:  one containing all previous
seizures, and one containing the new seizure.  Only matches within the
new seizure or between new and old are reported; matches between old
seizures are not.

If you need to get matches between all seizures old and new, this can be done 
by placing just one sample (it does not matter which) in the "old" seizure file
and all other samples in the new seizure file.   Note that this will take
a long time to run (around five days on Mary's laptop).

1)  Make a directory named "fammatch" under each species-specific 
run directory, and copy into it:

The appropriate reference file REFELE_[DBno]_[species]_long.csv
made in step D2.

The R scripts calculate_LRs.R and LR_functions.R, found in the src
directory.

The python scripts 1_add_seizures.py, 2_filter_results.py, and
3_seizure_analysis.py, found in the src directory.
(There is a fourth script distributed with the familial matching code,
4_remove_seizures.py, but this pipeline does not use it.  It is also
present in src if you find a use for it.)

The python script partition_genotypes.py found in the src directory.

2)  Provide the official name of your seizure and a copy of the file(s)
PREFIX_genotypes_[species]_wide.csv made in step D2 to the
person in charge of updating the seizure genotypes and metadata files.
Receive updated copies of seizure_[species]_wide.csv and 
seizure_metadata.tsv from the maintainer and place them in the appropriate
fammatch directory for their species.

3)  Create input files for familial matching.  Run the Python program
partition_genotypes.py as follows:

python3 partition_genotypes.py [species] PREFIX_genotypes_[species]_wide.csv seizure_[species]_wide.csv

This will write a file for the "old" seizure data, excluding the current
seizure, called other_genoptypes_[species]_wide.csv. 

This program will fail with an error message to screen if your seizure
has not been added to seizure_genotypes.csv and seizure_metadata.tsv.
If this happens, ask the maintainer to correctly update these files, obtain
updated copies, and try again.

4)  Run the familial matching program.  This step will overwrite 
any previous results from familial matching for the same species that are 
present in its directory.  If there are results you wish to keep,
move them away or rename them before running it.

Run calculate_LRs.R (Rscript command).  The arguments are 
[species], REFELE_[DBno]_[species]_long.csv,
other_genotypes_[species]_wide.csv, and PREFIX_genotypes_[species]_wide.csv.

This writes obsLRs_[species].txt, which contains all pairwise match
scores between old x new seizures and new x new seizures. 

4)  Run 1_add_seizures.py as follows:

python 1_add_seizures.py --input_file obsLRs.[species].txt --seizure_file seizure_metadata.tsv

This writes obsLRs.[species].seizures.txt which is annotated with seizure
names.

5)  Run 2_filter_results.py.  This program filters out non-significant matches
according to a given cutoff.  Internal documentation says that the cutoff is
"on log10 scale" and that it also enforces 10+ loci.  Published work uses
a cutoff of 2.0.  Command line as follows:

python 2_filter_results.py --input_file obsLRs.[species].seizures.txt --cutoff 2.0

Note that if you mistakenly use obsLRs.[species].txt this program will
appear to work fine, but downstream code will NOT.   It writes
obsLRs.[species].2.0.filtered.txt.

6)  Run 3_seizure_analysis.py:

python 3_seizure_analysis.py --filtered_file obsLRs.[species].seizures.2.0.filtered.txt

This will write obsLRs.[species].seizures.2.0.filtered.seizanalysis.txt, which
summarizes comparisons between seizures.  For interpreting the results you
will use both obsLRs.[species].2.0.filtered.txt and this file.
